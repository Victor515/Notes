Gradient descent

analyze the network



labeling - the answer to one data sample

cost function: square of diff(network output, answer)



how to find the point where cost function is at minimum: gradient descent

**gradient**: the direction of steepest increase

negative of gradient is what we need



algorithm behind training neural networks: backpropagation

Learning: the process of minimizing cost functions